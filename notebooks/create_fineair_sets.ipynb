{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murat/Projects/satellitepy/venv_satellitepy/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(pow(2,40)).__str__()\n",
    "from satellitepy.data.labels import read_label, init_satellitepy_label, set_image_keys, get_all_satellitepy_keys\n",
    "from satellitepy.utils.path_utils import get_file_paths, create_folder\n",
    "from satellitepy.data.utils import get_satellitepy_dict_values, count_unique_values, get_satellitepy_table, read_img, set_satellitepy_dict_values\n",
    "from satellitepy.data.bbox import BBox\n",
    "from satellitepy.data.patch import is_truncated, shift_bboxes, create_patch_polygon, get_intersection\n",
    "from satellitepy.data.tools import show_labels_on_images\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_dataset/images/\")\n",
    "# label_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_dataset/labels_fineair/role_th_50/\")\n",
    "# label_format = 'fineair' # \n",
    "# test_img_sz = 8000\n",
    "# intersection_th = 0.91\n",
    "# test_sum_ratio_th = 0.15\n",
    "# bbox_for_intersection = 'dbboxes'\n",
    "# delete_output_files = True\n",
    "# input_img_ext = 'tif'\n",
    "# img_read_module = 'rasterio'\n",
    "\n",
    "# train_label_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/train/labels_alpha\")\n",
    "# train_img_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha\")\n",
    "# test_label_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/labels_alpha\")\n",
    "# test_img_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/images_alpha\")\n",
    "\n",
    "\n",
    "# for folder in [train_img_folder, train_label_folder, test_img_folder, test_label_folder]:\n",
    "#     assert create_folder(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha\")\n",
    "label_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/train/labels_alpha\")\n",
    "label_format = 'satellitepy' # \n",
    "test_img_sz = 6000\n",
    "intersection_th = 0.91\n",
    "test_sum_ratio_th = 0.15\n",
    "bbox_for_intersection = 'obboxes'\n",
    "img_read_module = 'cv2'\n",
    "input_img_ext = 'png'\n",
    "delete_output_files = True\n",
    "\n",
    "train_label_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/only_train/labels_alpha\")\n",
    "train_img_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/only_train/images_alpha\")\n",
    "test_label_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/val/labels_alpha\")\n",
    "test_img_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/val/images_alpha\")\n",
    "\n",
    "for folder in [train_img_folder, train_label_folder, test_img_folder, test_label_folder]:\n",
    "    assert create_folder(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING! THIS WILL DELETE ALL IMAGES AND LABELS IN OUTPUT FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_files(folder_path):\n",
    "    folder = Path(folder_path)\n",
    "    for file in folder.iterdir():\n",
    "        if file.is_file():\n",
    "            file.unlink()\n",
    "\n",
    "if delete_output_files:\n",
    "    remove_all_files(test_img_folder)\n",
    "    remove_all_files(test_label_folder)\n",
    "    remove_all_files(train_img_folder)\n",
    "    remove_all_files(train_label_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get patch labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_dict(label, test_img_size, margin=100, intersection_th=0.95):\n",
    "\n",
    "    satellitepy_fac = get_satellitepy_table()['fineair-class']\n",
    "    \n",
    "    # Define patch starting coords\n",
    "    patch_start_coords = []\n",
    "    for i, bbox_corners in enumerate(label[bbox_for_intersection]):\n",
    "        bbox = BBox(corners=bbox_corners)\n",
    "        x_min, x_max, y_min, y_max = bbox.get_bbox_limits(bbox.corners)\n",
    "        x_0, y_0 = np.maximum(x_min - margin,0), np.maximum(y_min - margin,0)\n",
    "        patch_start_coords.append([x_0,y_0])\n",
    "\n",
    "    # Set patch \n",
    "    patch_dict = {\n",
    "        'test_indices': [[] for _ in range(len(patch_start_coords))],\n",
    "        'train_indices':[[] for _ in range(len(patch_start_coords))],\n",
    "        'test_fac':[[] for _ in range(len(patch_start_coords))],\n",
    "        'test_fac_count':[[0 for fac_i in range(len(set(satellitepy_fac.values())))] for _ in range(len(patch_start_coords))],\n",
    "        'train_fac':[[] for _ in range(len(patch_start_coords))],\n",
    "        'train_fac_count':[[0 for fac_i in range(len(set(satellitepy_fac.values())))] for _ in range(len(patch_start_coords))],\n",
    "        'start_coords': patch_start_coords,\n",
    "        }\n",
    "    for i, patch_start_coord in enumerate(patch_start_coords):\n",
    "        x_0, y_0 = patch_start_coord\n",
    "        patch_polygon = create_patch_polygon(x_0=x_0, y_0=y_0, patch_size=test_img_size)\n",
    "        fineair_classes = get_satellitepy_dict_values(label,task='fineair-class')\n",
    "        for j, bbox_corners in enumerate(label[bbox_for_intersection]):\n",
    "            intersection = get_intersection(bbox_corners=bbox_corners, patch_polygon=patch_polygon)\n",
    "            # is_truncated_bbox = is_truncated(bbox_corners=bbox_corners, patch_polygon=patch_polygon, relative_area_threshold=relative_area_thr)\n",
    "            ## Set the labels to empty because of cutoff objects\n",
    "            if intersection == 0:\n",
    "                continue\n",
    "            if intersection > 0 and intersection_th > intersection:\n",
    "                # patch_dict['labels'][i] = []\n",
    "                patch_dict['test_indices'][i] = []\n",
    "                patch_dict['test_fac'][i] = []\n",
    "                break\n",
    "            else:\n",
    "                # patch_dict['labels'][i] = set_image_keys(get_all_satellitepy_keys(), patch_dict['labels'][i], label, j)\n",
    "                patch_dict['test_indices'][i].append(j)\n",
    "                patch_dict['test_fac'][i].append(fineair_classes[j])\n",
    "        patch_dict['train_indices'][i] = list(set(range(len(label[bbox_for_intersection])))-set(patch_dict['test_indices'][i]))\n",
    "        patch_dict['train_fac'][i] = [fineair_classes[j] for j in patch_dict['train_indices'][i]]\n",
    "\n",
    "        # Set train fac count and test fac count\n",
    "        for fac in patch_dict['train_fac'][i]:\n",
    "            fac_i = satellitepy_fac[fac]\n",
    "            patch_dict['train_fac_count'][i][fac_i] += 1 \n",
    "        for fac in patch_dict['test_fac'][i]:\n",
    "            fac_i = satellitepy_fac[fac]\n",
    "            patch_dict['test_fac_count'][i][fac_i] += 1\n",
    "    return patch_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murat/Projects/satellitepy/venv_satellitepy/lib/python3.10/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "label_paths = get_file_paths(label_folder)\n",
    "\n",
    "\n",
    "patch_dicts = {}\n",
    "\n",
    "for label_path in label_paths:\n",
    "    label = read_label(label_path=label_path,label_format=label_format)\n",
    "    patch_dict = get_patch_dict(label=label,test_img_size=test_img_sz, intersection_th=intersection_th)\n",
    "    label_file_name = label_path.name\n",
    "    patch_dicts[label_file_name] = patch_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one patch from each original image for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_lists_with_indices(list_of_lists):\n",
    "    unique_dict = {}\n",
    "    \n",
    "    for idx, sublist in enumerate(list_of_lists):\n",
    "        # Convert the list to a tuple so it can be used as a dictionary key\n",
    "        tuple_sublist = tuple(sublist)\n",
    "        \n",
    "        # Store the sublist and its first occurrence index if it's unique\n",
    "        if tuple_sublist not in unique_dict:\n",
    "            unique_dict[tuple_sublist] = idx\n",
    "    \n",
    "    # Extract unique lists and their indices\n",
    "    unique_lists = [list(key) for key in unique_dict.keys()]\n",
    "    unique_indices = list(unique_dict.values())\n",
    "    \n",
    "    return unique_lists, unique_indices\n",
    "\n",
    "# Test case\n",
    "# input_list = [[1, 1], [2, 2], [1, 1]]\n",
    "# unique_lists, unique_indices = unique_lists_with_indices(input_list)\n",
    "# print(\"Unique Lists:\", unique_lists)\n",
    "# print(\"Indices of First Occurrences:\", unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_train_pairs(patch_dicts):\n",
    "    \n",
    "    orig_test_train_pair_indices = []\n",
    "    all_test_train_pairs = []\n",
    "    all_test_train_pair_indices = []\n",
    "    # Iterate through each dictionary in B\n",
    "    for img_name, patch_dict in patch_dicts.items():\n",
    "        test_indices, unique_patch_indices = unique_lists_with_indices(patch_dict['test_indices'])\n",
    "        ## Remove empty list from test indices\n",
    "        if len(unique_patch_indices) == 0:\n",
    "            print(img_name)\n",
    "        else:\n",
    "            for i, test_ind in enumerate(test_indices.copy()):\n",
    "                if test_ind == []:\n",
    "                    test_indices.pop(i)\n",
    "                    unique_patch_indices.pop(i)\n",
    "        train_indices = [ind for i, ind in enumerate(patch_dict['train_indices']) if i in unique_patch_indices]\n",
    "        # if img_name == 'O_Hare_Int_Airport_23FEB28165710.json':\n",
    "        #     print(patch_dict['train_indices'])\n",
    "        # train_fac = [fac for i, fac in enumerate(patch_dict['train_fac']) if i in unique_patch_indices]\n",
    "        # test_fac = [fac for i, fac in enumerate(patch_dict['test_fac']) if i in unique_patch_indices]\n",
    "        test_fac_count = [fac for i, fac in enumerate(patch_dict['test_fac_count']) if i in unique_patch_indices]\n",
    "        train_fac_count = [fac for i, fac in enumerate(patch_dict['train_fac_count']) if i in unique_patch_indices]\n",
    "        test_train_pairs = list(zip(test_fac_count, train_fac_count))\n",
    "        test_train_pair_indices = list(zip(test_indices, train_indices))\n",
    "        all_test_train_pairs.append(test_train_pairs)\n",
    "        all_test_train_pair_indices.append(test_train_pair_indices)\n",
    "        orig_test_train_pair_indices.append(unique_patch_indices)\n",
    "    return all_test_train_pairs, all_test_train_pair_indices, orig_test_train_pair_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_pairs, test_train_pair_indices, orig_test_train_pair_indices = compute_test_train_pairs(patch_dicts)\n",
    "# print(test_train_pair_indices[0][17])\n",
    "# print(orig_test_train_pair_indices)\n",
    "# print(list(patch_dicts.values())[0]['test_indices'][17])\n",
    "# print(list(patch_dicts.values())[0]['train_indices'])\n",
    "\n",
    "for i, s in enumerate(test_train_pairs):\n",
    "    if len(s) <= 0:\n",
    "        print(s)\n",
    "        print(len(s),i)\n",
    "        print(list(patch_dicts.keys())[i])\n",
    "        print(list(patch_dicts.values())[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesian options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of elements in each set\n",
    "# lengths = [len(s) for s in test_train_pairs]\n",
    "\n",
    "def cartesian_with_indices(all_test_train_pairs):\n",
    "    # Calculate the product of all test-train pairs across dictionaries in B\n",
    "    for combination in itertools.product(*all_test_train_pairs):\n",
    "         # Find indices of elements in their respective sets\n",
    "        indices = [s.index(elem) for s, elem in zip(all_test_train_pairs, combination)]\n",
    "        yield combination, indices\n",
    "\n",
    "def random_cartesian_with_indices(sets, num_samples):\n",
    "    for _ in range(num_samples):\n",
    "        # Randomly choose an index for each set\n",
    "        indices = [random.randint(0, len(s) - 1) for s in sets]\n",
    "        # Get the elements at the chosen indices\n",
    "        sample = [sets[i][index] for i, index in enumerate(indices)]\n",
    "        yield sample, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cartesian_test_train_pairs(sets, test_sum_ratio_th):\n",
    "    best_indices = [0]*len(sets)\n",
    "    best_sum_ratio_dif = np.inf\n",
    "    best_test_to_all_ratio = np.Inf\n",
    "    # for combination, indices in cartesian_with_indices(sets):\n",
    "    for combination, indices in random_cartesian_with_indices(test_train_pairs, 300000):\n",
    "\n",
    "        test_sum = np.sum(np.array(combination)[:,0],axis=0)\n",
    "        train_sum = np.sum(np.array(combination)[:,1],axis=0)\n",
    "        total_sum = np.sum(a=[test_sum,train_sum],axis=1)\n",
    "\n",
    "        test_sum_ratio = test_sum / total_sum[0]\n",
    "        train_sum_ratio = train_sum / total_sum[1]\n",
    "        test_to_all_ratio = total_sum[0]/np.sum(total_sum)\n",
    "        sum_ratio_dif = np.sum(np.abs(test_sum_ratio-train_sum_ratio)) # train and test set ratio difference\n",
    "\n",
    "        if (best_test_to_all_ratio+0.001 >= np.abs(test_to_all_ratio-test_sum_ratio_th)) and (sum_ratio_dif <= best_sum_ratio_dif):\n",
    "            print('# Test instances: ', test_sum)\n",
    "            print('# Train instances: ',train_sum)\n",
    "            print('# Total instances (ratio): ', total_sum, test_to_all_ratio)\n",
    "            print('Absolute sum diff: ', sum_ratio_dif)\n",
    "            print(indices)\n",
    "            best_sum_ratio_dif = sum_ratio_dif\n",
    "            best_test_to_all_ratio = np.abs(test_to_all_ratio-test_sum_ratio_th)\n",
    "            best_indices = indices\n",
    "    return best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test instances:  [10 17 77 67 20  0  6  0 74 90  3 10 16 23 19  1  2  7  0 11  0 84 15]\n",
      "# Train instances:  [ 66 164 540 438 188   0 127   0 764 780  50  53 133 269 128  56  59  95  53  86   0 710 209]\n",
      "# Total instances (ratio):  [ 552 4968] 0.1\n",
      "Absolute sum diff:  0.2101449275362319\n",
      "[26, 1, 18, 12, 28, 36, 10, 24, 18, 2, 21, 7, 36, 9, 5, 4, 9, 23, 12, 23, 16, 24, 17, 21, 5, 10, 1, 9, 19, 12, 12, 3, 1, 20, 19, 7, 6, 12, 3, 6, 13]\n",
      "# Test instances:  [ 15  22  83  62  26   0  27   0 110 138  12   4  16  53  20   8  16  12  19  18   0 109  31]\n",
      "# Train instances:  [ 61 159 534 443 182   0 106   0 728 732  41  59 133 239 127  49  45  90  34  79   0 685 193]\n",
      "# Total instances (ratio):  [ 801 4719] 0.1451086956521739\n",
      "Absolute sum diff:  0.17742443687285364\n",
      "[10, 12, 16, 7, 14, 23, 13, 16, 12, 0, 6, 9, 32, 22, 23, 19, 18, 18, 6, 11, 16, 5, 13, 31, 7, 11, 1, 5, 0, 22, 34, 20, 19, 22, 15, 0, 11, 11, 5, 25, 9]\n",
      "# Test instances:  [ 15  28  89  83  29   0  20   0 107 131   2   8  17  42  27  15   5  15   1  13   0 142  51]\n",
      "# Train instances:  [ 61 153 528 422 179   0 113   0 731 739  51  55 132 250 120  42  56  87  52  84   0 652 173]\n",
      "# Total instances (ratio):  [ 840 4680] 0.15217391304347827\n",
      "Absolute sum diff:  0.16593406593406593\n",
      "[9, 8, 13, 6, 11, 31, 16, 30, 18, 5, 7, 7, 15, 50, 7, 21, 4, 12, 15, 22, 31, 20, 10, 18, 12, 5, 0, 14, 2, 27, 4, 15, 20, 22, 13, 19, 22, 7, 4, 24, 16]\n",
      "# Test instances:  [ 10  27  92  70  24   0  15   0 130 127   7  10  21  33  19  14  14  21  20  24   0 114  34]\n",
      "# Train instances:  [ 66 154 525 435 184   0 118   0 708 743  46  53 128 259 128  43  47  81  33  73   0 680 190]\n",
      "# Total instances (ratio):  [ 826 4694] 0.14963768115942028\n",
      "Absolute sum diff:  0.12326797075448442\n",
      "[12, 16, 17, 1, 10, 15, 25, 27, 15, 12, 11, 9, 8, 49, 36, 21, 11, 36, 3, 21, 25, 0, 4, 5, 11, 3, 18, 11, 19, 5, 33, 25, 18, 22, 16, 4, 15, 9, 10, 21, 0]\n",
      "# Test instances:  [  8  20  90  78  34   0  28   0 124 112   9  14  28  42  19  10  12  15   8   9   0 121  44]\n",
      "# Train instances:  [ 68 161 527 427 174   0 105   0 714 758  44  49 121 250 128  47  49  87  45  88   0 673 180]\n",
      "# Total instances (ratio):  [ 825 4695] 0.14945652173913043\n",
      "Absolute sum diff:  0.12042211249878981\n",
      "[10, 15, 22, 19, 4, 8, 18, 7, 12, 15, 14, 28, 42, 2, 48, 21, 16, 8, 14, 13, 29, 30, 1, 11, 6, 11, 7, 17, 1, 2, 31, 13, 0, 15, 27, 15, 11, 20, 6, 2, 8]\n",
      "# Test instances:  [ 10  25 102  80  28   0  23   0 123 131   7   7  22  50  22   6   2   9  15   9   0 122  35]\n",
      "# Train instances:  [ 66 156 515 425 180   0 110   0 715 739  46  56 127 242 125  51  59  93  38  88   0 672 189]\n",
      "# Total instances (ratio):  [ 828 4692] 0.15\n",
      "Absolute sum diff:  0.09889173060528561\n",
      "[19, 0, 0, 5, 13, 20, 3, 12, 22, 5, 19, 16, 32, 45, 44, 7, 17, 38, 8, 7, 33, 26, 10, 12, 9, 9, 6, 15, 20, 11, 18, 9, 30, 17, 10, 11, 20, 6, 15, 0, 2]\n",
      "# Test instances:  [ 14  22  95  68  31   0  16   0 123 131   2  10  20  44  30  10  15  11   8  17   0 131  33]\n",
      "# Train instances:  [ 62 159 522 437 177   0 117   0 715 739  51  53 129 248 117  47  46  91  45  80   0 663 191]\n",
      "# Total instances (ratio):  [ 831 4689] 0.15054347826086956\n",
      "Absolute sum diff:  0.09704100464024795\n",
      "[19, 3, 3, 20, 9, 13, 17, 5, 7, 3, 17, 20, 44, 12, 5, 19, 6, 8, 16, 17, 5, 23, 18, 31, 9, 3, 35, 10, 5, 28, 31, 2, 1, 19, 16, 6, 16, 3, 1, 24, 8]\n"
     ]
    }
   ],
   "source": [
    "result = get_cartesian_test_train_pairs(test_train_pairs, test_sum_ratio_th=test_sum_ratio_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 3, 3, 20, 9, 13, 17, 5, 7, 3, 17, 20, 44, 12, 5, 19, 6, 8, 16, 17, 5, 23, 18, 31, 9, 3, 35, 10, 5, 28, 31, 2, 1, 19, 16, 6, 16, 3, 1, 24, 8]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_sets(patch_dicts,best_indices,test_train_pair_indices, orig_test_train_pair_indices):\n",
    "    \n",
    "    # for file_name, patch_dict in patch_dicts.items():\n",
    "    file_names = list(patch_dicts.keys())\n",
    "    tasks = get_all_satellitepy_keys()\n",
    "    for i, ind in enumerate(best_indices):\n",
    "        # i : original image index\n",
    "        # ind : patch index within the original image\n",
    "\n",
    "        orig_ind = orig_test_train_pair_indices[i][ind]\n",
    "        # Save labels\n",
    "        file_name = Path(file_names[i]).stem\n",
    "        print(f'Processing {file_name}')\n",
    "        train_img_path = train_img_folder/f\"{file_name}.png\"\n",
    "        if train_img_path.is_file():\n",
    "             print(f'{file_name} exists in the destination train folder, skipped...')\n",
    "             continue\n",
    "        patch_dict = patch_dicts[file_names[i]]\n",
    "        label_path = label_folder / file_names[i]\n",
    "        label = read_label(label_path=label_path,label_format=label_format)\n",
    "        test_label = init_satellitepy_label()\n",
    "        train_label = init_satellitepy_label()\n",
    "        x_0, y_0 = patch_dict['start_coords'][orig_ind]\n",
    "\n",
    "        # Set test and train labels\n",
    "        ## Unique values are calculated previously for test_train_pairs\n",
    "        ## Use the corresponding unique value indices to find the train-test pair indices\n",
    "        test_indices, train_indices = test_train_pair_indices[i][ind]\n",
    "\n",
    "        # print(test_indices)\n",
    "        print(f\"Test image has {len(test_indices)} airplanes.\")\n",
    "        # print(train_indices)\n",
    "        # if len(test_indices) == 0:\n",
    "        #     print(f\"{file_name} has no test objects, original image will be saved into the train folder.\")\n",
    "        #     train_label_path = train_label_folder / f\"{file_name}.json\"\n",
    "        #     with open(str(train_label_path), 'w') as f:\n",
    "        #         json.dump(train_label, f, indent=4)\n",
    "        #     img = read_img(img_path=img_folder/f\"{file_name}.tif\", module='rasterio')\n",
    "        #     cv2.imwrite(str(train_img_folder/f\"{file_name}.png\"),img)\n",
    "        #     continue\n",
    "        for task in tasks:\n",
    "            task_values = get_satellitepy_dict_values(label,task=task)\n",
    "            test_task_values = []\n",
    "            train_task_values = []\n",
    "            for task_value_i, task_value in enumerate(task_values):\n",
    "                if task_value_i in test_indices:\n",
    "                    test_task_values.append(task_value)\n",
    "                elif task_value_i in train_indices:\n",
    "                    train_task_values.append(task_value)\n",
    "            test_label = set_satellitepy_dict_values(test_label,task=task,value=test_task_values)\n",
    "            train_label = set_satellitepy_dict_values(train_label,task=task,value=train_task_values)\n",
    "\n",
    "        # shift test bboxes\n",
    "        for bbox_task in ['obboxes','hbboxes']:\n",
    "            bbox_values = get_satellitepy_dict_values(test_label,task=bbox_task)\n",
    "            shifted_bbox_values = (np.array(bbox_values) - [x_0, y_0]).tolist()\n",
    "            test_label = set_satellitepy_dict_values(test_label,task=bbox_task,value=shifted_bbox_values)\n",
    "\n",
    "        test_file_name = f'{file_name}_x0_{x_0}_y0_{y_0}_sz_{test_img_sz}'\n",
    "        test_label_path = test_label_folder / f\"{test_file_name}.json\"\n",
    "        train_label_path = train_label_folder / f\"{file_name}.json\"\n",
    "\n",
    "        with open(str(test_label_path), 'w+') as f:\n",
    "                json.dump(test_label, f, indent=4)\n",
    "        with open(str(train_label_path), 'w+') as f:\n",
    "                json.dump(train_label, f, indent=4)\n",
    "\n",
    "        # Save images\n",
    "        print(f\"Saving train image to {str(train_img_path)}...\")\n",
    "        img = read_img(img_path=str(img_folder/f\"{file_name}.{input_img_ext}\"), module=img_read_module)\n",
    "        test_img = img[y_0:y_0+test_img_sz, x_0:x_0+test_img_sz, :]\n",
    "        train_mask = np.ones_like(img, dtype=np.uint8)\n",
    "        train_mask[y_0:y_0+test_img_sz, x_0:x_0+test_img_sz, :] = 0\n",
    "        train_img = img*train_mask\n",
    "        cv2.imwrite(str(train_img_path),train_img)\n",
    "        cv2.imwrite(str(test_img_folder/f\"{test_file_name}.png\"),test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Amsterdam_23MAR14104929\n",
      "Test image has 5 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Amsterdam_23MAR14104929.png...\n",
      "Processing Bangkok_23FEB21040003\n",
      "Test image has 1 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Bangkok_23FEB21040003.png...\n",
      "Processing Beijing_23SEP13031225\n",
      "Test image has 5 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Beijing_23SEP13031225.png...\n",
      "Processing Beijing_Capital_International_22DEC04031345\n",
      "Test image has 12 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Beijing_Capital_International_22DEC04031345.png...\n",
      "Processing Cairo_24JAN04084426\n",
      "Test image has 14 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Cairo_24JAN04084426.png...\n",
      "Processing Cairo_24JAN29084910\n",
      "Test image has 47 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Cairo_24JAN29084910.png...\n",
      "Processing Charles_De_Gaulle_23MAY29105259\n",
      "Test image has 34 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Charles_De_Gaulle_23MAY29105259.png...\n",
      "Processing Charlotte_Douglas_International_Airport_24JAN18161805\n",
      "Test image has 53 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Charlotte_Douglas_International_Airport_24JAN18161805.png...\n",
      "Processing Chengdu_Shuangliu_International_Airport_23NOV27035335\n",
      "Test image has 48 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Chengdu_Shuangliu_International_Airport_23NOV27035335.png...\n",
      "Processing Chongqing_Jiangbei_International_Airport_23JUL16034146\n",
      "Test image has 45 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Chongqing_Jiangbei_International_Airport_23JUL16034146.png...\n",
      "Processing Dallas_Fort_Worth_21JUL13170358\n",
      "Test image has 38 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Dallas_Fort_Worth_21JUL13170358.png...\n",
      "Processing Dallas_Fort_Worth_22JUN16172659\n",
      "Test image has 4 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Dallas_Fort_Worth_22JUN16172659.png...\n",
      "Processing Dallas_Fort_Worth_23FEB22171239\n",
      "Test image has 2 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Dallas_Fort_Worth_23FEB22171239.png...\n",
      "Processing Denver_International_Airport_23JUN19175130\n",
      "Test image has 3 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Denver_International_Airport_23JUN19175130.png...\n",
      "Processing Denver_International_Airport_24JAN23173709\n",
      "Test image has 6 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Denver_International_Airport_24JAN23173709.png...\n",
      "Processing Dubai_International_23DEC03070208\n",
      "Test image has 65 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Dubai_International_23DEC03070208.png...\n",
      "Processing Frankfurt_22MAR22103647\n",
      "Test image has 2 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Frankfurt_22MAR22103647.png...\n",
      "Processing George_Bush_Int_Airport_23DEC05171248\n",
      "Test image has 23 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/George_Bush_Int_Airport_23DEC05171248.png...\n",
      "Processing Guangzhou_Baiyun_International_Airport_22OCT10032231\n",
      "Test image has 4 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Guangzhou_Baiyun_International_Airport_22OCT10032231.png...\n",
      "Processing Harry_Reid_International_Airport_23NOV25183153\n",
      "Test image has 18 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Harry_Reid_International_Airport_23NOV25183153.png...\n",
      "Processing Hartsfield_Jackson_23SEP23162708\n",
      "Test image has 7 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Hartsfield_Jackson_23SEP23162708.png...\n",
      "Processing Houston_23SEP01171626\n",
      "Test image has 14 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Houston_23SEP01171626.png...\n",
      "Processing Istanbul_23JUL12090526\n",
      "Test image has 54 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Istanbul_23JUL12090526.png...\n",
      "Processing John_F_Kennedy_Airport_23FEB05160037\n",
      "Test image has 24 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/John_F_Kennedy_Airport_23FEB05160037.png...\n",
      "Processing King_Fahd_23JUL18072645\n",
      "Test image has 4 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/King_Fahd_23JUL18072645.png...\n",
      "Processing King_Fahd_24FEB13071831\n",
      "Test image has 11 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/King_Fahd_24FEB13071831.png...\n",
      "Processing Madrid_23MAR28111507\n",
      "Test image has 8 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Madrid_23MAR28111507.png...\n",
      "Processing Miami_International_Airport_23OCT17160943\n",
      "Test image has 9 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Miami_International_Airport_23OCT17160943.png...\n",
      "Processing O_Hare_Int_Airport_22JUN14165415\n",
      "Test image has 3 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/O_Hare_Int_Airport_22JUN14165415.png...\n",
      "Processing O_Hare_Int_Airport_22OCT23164249\n",
      "Test image has 10 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/O_Hare_Int_Airport_22OCT23164249.png...\n",
      "Processing O_Hare_Int_Airport_23FEB28165710\n",
      "Test image has 51 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/O_Hare_Int_Airport_23FEB28165710.png...\n",
      "Processing Orlando_International_Airport_23MAY30161635\n",
      "Test image has 1 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Orlando_International_Airport_23MAY30161635.png...\n",
      "Processing Orlando_International_Airport_23NOV07161938\n",
      "Test image has 42 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Orlando_International_Airport_23NOV07161938.png...\n",
      "Processing Orlando_International_Airport_24FEB16160844\n",
      "Test image has 14 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Orlando_International_Airport_24FEB16160844.png...\n",
      "Processing Shanghai_23APR13022829\n",
      "Test image has 3 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Shanghai_23APR13022829.png...\n",
      "Processing Shenzhen_23APR28030710\n",
      "Test image has 21 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Shenzhen_23APR28030710.png...\n",
      "Processing Singapore_22SEP27034737\n",
      "Test image has 19 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Singapore_22SEP27034737.png...\n",
      "Processing Soekarno_22MAR27031534\n",
      "Test image has 1 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Soekarno_22MAR27031534.png...\n",
      "Processing Tokyo_Haneda_Airport_24JAN30012936\n",
      "Test image has 20 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Tokyo_Haneda_Airport_24JAN30012936.png...\n",
      "Processing Toronto_23MAY27162713\n",
      "Test image has 74 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Toronto_23MAY27162713.png...\n",
      "Processing Washington_Dulles_23MAR30160557\n",
      "Test image has 12 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha/Washington_Dulles_23MAR30160557.png...\n"
     ]
    }
   ],
   "source": [
    "save_sets(patch_dicts=patch_dicts,\n",
    "    best_indices=result,\n",
    "    test_train_pair_indices=test_train_pair_indices,\n",
    "    orig_test_train_pair_indices=orig_test_train_pair_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_labels_on_images(image_folder=test_img_folder,\n",
    "#         label_folder=test_label_folder,\n",
    "#         mask_folder=None,\n",
    "#         label_format='satellitepy',\n",
    "#         img_read_module='cv2',\n",
    "#         out_folder=Path('/home/murat/Projects/satellitepy/docs/temp_fineair_set'),\n",
    "#         tasks=['coarse-class','obboxes'],\n",
    "#         rescaling=1.0,\n",
    "#         interpolation_method=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_satellitepy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
