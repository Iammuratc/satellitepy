{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murat/Projects/satellitepy/venv_satellitepy/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(pow(2,40)).__str__()\n",
    "from satellitepy.data.labels import read_label, init_satellitepy_label, set_image_keys, get_all_satellitepy_keys\n",
    "from satellitepy.utils.path_utils import get_file_paths, create_folder\n",
    "from satellitepy.data.utils import get_satellitepy_dict_values, count_unique_values, get_satellitepy_table, read_img, set_satellitepy_dict_values\n",
    "from satellitepy.data.bbox import BBox\n",
    "from satellitepy.data.patch import is_truncated, shift_bboxes, create_patch_polygon, get_intersection\n",
    "from satellitepy.data.tools import show_labels_on_images\n",
    "\n",
    "\n",
    "from rasterio.windows import Window\n",
    "import rasterio\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_dataset/images/\")\n",
    "# label_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_dataset/labels_fineair/role_th_50/\")\n",
    "# label_format = 'fineair' # \n",
    "# test_img_sz = 8000\n",
    "# intersection_th = 0.91\n",
    "# test_sum_ratio_th = 0.15\n",
    "# bbox_for_intersection = 'dbboxes'\n",
    "# delete_output_files = False\n",
    "# input_img_ext = 'tif'\n",
    "# img_read_module = 'rasterio'\n",
    "\n",
    "# # Output folders\n",
    "# output_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets_v2\")\n",
    "# train_label_png_folder = output_folder/\"png\"/\"train_val\"/\"labels\"\n",
    "# train_label_tif_folder = output_folder/\"tif\"/\"train_val\"/\"labels\"\n",
    "# train_img_png_folder = output_folder/\"png\"/\"train_val\"/\"images\"\n",
    "# train_img_tif_folder = output_folder/\"tif\"/\"train_val\"/\"images\"\n",
    "# # train_img_folder = output_folder/\"train_val\"/\"images\" # Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/train_val/images\")\n",
    "# test_label_png_folder = output_folder/\"png\"/\"test\"/\"labels\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/labels\")\n",
    "# test_label_tif_folder = output_folder/\"tif\"/\"test\"/\"labels\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/labels\")\n",
    "# # test_label_folder = output_folder/\"test\"/\"labels\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/labels\")\n",
    "# test_img_png_folder = output_folder/\"png\"/\"test\"/\"images\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/images\")\n",
    "# test_img_tif_folder = output_folder/\"tif\"/\"test\"/\"images\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/images\")\n",
    "# # test_img_folder = output_folder/\"test\"/\"images\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/images\")\n",
    "\n",
    "\n",
    "# # for folder in [train_img_folder, train_label_folder, test_img_folder, test_label_folder]:\n",
    "# for folder in [train_label_png_folder,\n",
    "#     train_label_tif_folder,\n",
    "#     train_img_png_folder,\n",
    "#     train_img_tif_folder,\n",
    "#     test_label_png_folder,\n",
    "#     test_label_tif_folder,\n",
    "#     test_img_png_folder,\n",
    "#     test_img_tif_folder]:\n",
    "#     assert create_folder(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets_v2\")\n",
    "# img_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/train/images_alpha\")\n",
    "img_folder = output_folder/\"tif\"/\"train_val\"/\"images\"\n",
    "# label_folder = Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/train/labels_alpha\")\n",
    "label_folder = output_folder/\"tif\"/\"train_val\"/\"labels\"\n",
    "\n",
    "\n",
    "label_format = 'satellitepy' # \n",
    "test_img_sz = 6000\n",
    "intersection_th = 0.91\n",
    "test_sum_ratio_th = 0.15\n",
    "bbox_for_intersection = 'obboxes'\n",
    "# img_read_module = 'cv2'\n",
    "# input_img_ext = 'png'\n",
    "input_img_ext = 'tif'\n",
    "img_read_module = 'rasterio'\n",
    "delete_output_files = False\n",
    "\n",
    "train_label_png_folder = output_folder/\"png\"/\"train\"/\"labels\"\n",
    "train_label_tif_folder = output_folder/\"tif\"/\"train\"/\"labels\"\n",
    "train_img_png_folder = output_folder/\"png\"/\"train\"/\"images\"\n",
    "train_img_tif_folder = output_folder/\"tif\"/\"train\"/\"images\"\n",
    "# train_img_folder = output_folder/\"train_val\"/\"images\" # Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/train_val/images\")\n",
    "test_label_png_folder = output_folder/\"png\"/\"val\"/\"labels\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/labels\")\n",
    "test_label_tif_folder = output_folder/\"tif\"/\"val\"/\"labels\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/labels\")\n",
    "# test_label_folder = output_folder/\"test\"/\"labels\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/labels\")\n",
    "test_img_png_folder = output_folder/\"png\"/\"val\"/\"images\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/images\")\n",
    "test_img_tif_folder = output_folder/\"tif\"/\"val\"/\"images\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/images\")\n",
    "# test_img_folder = output_folder/\"test\"/\"images\" #Path(\"/mnt/2tb-1/satellitepy/data/FR24_sets/test/images\")\n",
    "\n",
    "\n",
    "# for folder in [train_img_folder, train_label_folder, test_img_folder, test_label_folder]:\n",
    "for folder in [train_label_png_folder,\n",
    "    train_label_tif_folder,\n",
    "    train_img_png_folder,\n",
    "    train_img_tif_folder,\n",
    "    test_label_png_folder,\n",
    "    test_label_tif_folder,\n",
    "    test_img_png_folder,\n",
    "    test_img_tif_folder]:\n",
    "    assert create_folder(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING! THIS WILL DELETE ALL IMAGES AND LABELS IN OUTPUT FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_files(folder_path):\n",
    "    folder = Path(folder_path)\n",
    "    for file in folder.iterdir():\n",
    "        if file.is_file():\n",
    "            file.unlink()\n",
    "\n",
    "if delete_output_files:\n",
    "    remove_all_files(test_img_folder)\n",
    "    remove_all_files(test_label_folder)\n",
    "    remove_all_files(train_img_folder)\n",
    "    remove_all_files(train_label_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get patch labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch_dict(label, test_img_size, margin=100, intersection_th=0.95):\n",
    "\n",
    "    satellitepy_fac = get_satellitepy_table()['fineair-class']\n",
    "    \n",
    "    # Define patch starting coords\n",
    "    patch_start_coords = []\n",
    "    for i, bbox_corners in enumerate(label[bbox_for_intersection]):\n",
    "        bbox = BBox(corners=bbox_corners)\n",
    "        x_min, x_max, y_min, y_max = bbox.get_bbox_limits(bbox.corners)\n",
    "        x_0, y_0 = np.maximum(x_min - margin,0), np.maximum(y_min - margin,0)\n",
    "        patch_start_coords.append([x_0,y_0])\n",
    "\n",
    "    # Set patch \n",
    "    patch_dict = {\n",
    "        'test_indices': [[] for _ in range(len(patch_start_coords))],\n",
    "        'train_indices':[[] for _ in range(len(patch_start_coords))],\n",
    "        'test_fac':[[] for _ in range(len(patch_start_coords))],\n",
    "        'test_fac_count':[[0 for fac_i in range(len(set(satellitepy_fac.values())))] for _ in range(len(patch_start_coords))],\n",
    "        'train_fac':[[] for _ in range(len(patch_start_coords))],\n",
    "        'train_fac_count':[[0 for fac_i in range(len(set(satellitepy_fac.values())))] for _ in range(len(patch_start_coords))],\n",
    "        'start_coords': patch_start_coords,\n",
    "        }\n",
    "    for i, patch_start_coord in enumerate(patch_start_coords):\n",
    "        x_0, y_0 = patch_start_coord\n",
    "        patch_polygon = create_patch_polygon(x_0=x_0, y_0=y_0, patch_size=test_img_size)\n",
    "        fineair_classes = get_satellitepy_dict_values(label,task='fineair-class')\n",
    "        for j, bbox_corners in enumerate(label[bbox_for_intersection]):\n",
    "            intersection = get_intersection(bbox_corners=bbox_corners, patch_polygon=patch_polygon)\n",
    "            # is_truncated_bbox = is_truncated(bbox_corners=bbox_corners, patch_polygon=patch_polygon, relative_area_threshold=relative_area_thr)\n",
    "            ## Set the labels to empty because of cutoff objects\n",
    "            if intersection == 0:\n",
    "                continue\n",
    "            if intersection > 0 and intersection_th > intersection:\n",
    "                # patch_dict['labels'][i] = []\n",
    "                patch_dict['test_indices'][i] = []\n",
    "                patch_dict['test_fac'][i] = []\n",
    "                break\n",
    "            else:\n",
    "                # patch_dict['labels'][i] = set_image_keys(get_all_satellitepy_keys(), patch_dict['labels'][i], label, j)\n",
    "                patch_dict['test_indices'][i].append(j)\n",
    "                patch_dict['test_fac'][i].append(fineair_classes[j])\n",
    "        patch_dict['train_indices'][i] = list(set(range(len(label[bbox_for_intersection])))-set(patch_dict['test_indices'][i]))\n",
    "        patch_dict['train_fac'][i] = [fineair_classes[j] for j in patch_dict['train_indices'][i]]\n",
    "\n",
    "        # Set train fac count and test fac count\n",
    "        for fac in patch_dict['train_fac'][i]:\n",
    "            fac_i = satellitepy_fac[fac]\n",
    "            patch_dict['train_fac_count'][i][fac_i] += 1 \n",
    "        for fac in patch_dict['test_fac'][i]:\n",
    "            fac_i = satellitepy_fac[fac]\n",
    "            patch_dict['test_fac_count'][i][fac_i] += 1\n",
    "    return patch_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murat/Projects/satellitepy/venv_satellitepy/lib/python3.10/site-packages/shapely/set_operations.py:133: RuntimeWarning: invalid value encountered in intersection\n",
      "  return lib.intersection(a, b, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "label_paths = get_file_paths(label_folder)\n",
    "\n",
    "\n",
    "patch_dicts = {}\n",
    "\n",
    "for label_path in label_paths:\n",
    "    label = read_label(label_path=label_path,label_format=label_format)\n",
    "    patch_dict = get_patch_dict(label=label,test_img_size=test_img_sz, intersection_th=intersection_th)\n",
    "    label_file_name = label_path.name\n",
    "    patch_dicts[label_file_name] = patch_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one patch from each original image for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_lists_with_indices(list_of_lists):\n",
    "    unique_dict = {}\n",
    "    \n",
    "    for idx, sublist in enumerate(list_of_lists):\n",
    "        # Convert the list to a tuple so it can be used as a dictionary key\n",
    "        tuple_sublist = tuple(sublist)\n",
    "        \n",
    "        # Store the sublist and its first occurrence index if it's unique\n",
    "        if tuple_sublist not in unique_dict:\n",
    "            unique_dict[tuple_sublist] = idx\n",
    "    \n",
    "    # Extract unique lists and their indices\n",
    "    unique_lists = [list(key) for key in unique_dict.keys()]\n",
    "    unique_indices = list(unique_dict.values())\n",
    "    \n",
    "    return unique_lists, unique_indices\n",
    "\n",
    "# Test case\n",
    "# input_list = [[1, 1], [2, 2], [1, 1]]\n",
    "# unique_lists, unique_indices = unique_lists_with_indices(input_list)\n",
    "# print(\"Unique Lists:\", unique_lists)\n",
    "# print(\"Indices of First Occurrences:\", unique_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_train_pairs(patch_dicts):\n",
    "    \n",
    "    orig_test_train_pair_indices = []\n",
    "    all_test_train_pairs = []\n",
    "    all_test_train_pair_indices = []\n",
    "    # Iterate through each dictionary in B\n",
    "    for img_name, patch_dict in patch_dicts.items():\n",
    "        test_indices, unique_patch_indices = unique_lists_with_indices(patch_dict['test_indices'])\n",
    "        ## Remove empty list from test indices\n",
    "        if len(unique_patch_indices) == 0:\n",
    "            print(img_name)\n",
    "        else:\n",
    "            for i, test_ind in enumerate(test_indices.copy()):\n",
    "                if test_ind == []:\n",
    "                    test_indices.pop(i)\n",
    "                    unique_patch_indices.pop(i)\n",
    "        train_indices = [ind for i, ind in enumerate(patch_dict['train_indices']) if i in unique_patch_indices]\n",
    "        # if img_name == 'O_Hare_Int_Airport_23FEB28165710.json':\n",
    "        #     print(patch_dict['train_indices'])\n",
    "        # train_fac = [fac for i, fac in enumerate(patch_dict['train_fac']) if i in unique_patch_indices]\n",
    "        # test_fac = [fac for i, fac in enumerate(patch_dict['test_fac']) if i in unique_patch_indices]\n",
    "        test_fac_count = [fac for i, fac in enumerate(patch_dict['test_fac_count']) if i in unique_patch_indices]\n",
    "        train_fac_count = [fac for i, fac in enumerate(patch_dict['train_fac_count']) if i in unique_patch_indices]\n",
    "        test_train_pairs = list(zip(test_fac_count, train_fac_count))\n",
    "        test_train_pair_indices = list(zip(test_indices, train_indices))\n",
    "        all_test_train_pairs.append(test_train_pairs)\n",
    "        all_test_train_pair_indices.append(test_train_pair_indices)\n",
    "        orig_test_train_pair_indices.append(unique_patch_indices)\n",
    "    return all_test_train_pairs, all_test_train_pair_indices, orig_test_train_pair_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_pairs, test_train_pair_indices, orig_test_train_pair_indices = compute_test_train_pairs(patch_dicts)\n",
    "# print(test_train_pair_indices[0][17])\n",
    "# print(orig_test_train_pair_indices)\n",
    "# print(list(patch_dicts.values())[0]['test_indices'][17])\n",
    "# print(list(patch_dicts.values())[0]['train_indices'])\n",
    "\n",
    "for i, s in enumerate(test_train_pairs):\n",
    "    if len(s) <= 0:\n",
    "        print(s)\n",
    "        print(len(s),i)\n",
    "        print(list(patch_dicts.keys())[i])\n",
    "        print(list(patch_dicts.values())[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cartesian options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of elements in each set\n",
    "# lengths = [len(s) for s in test_train_pairs]\n",
    "\n",
    "def cartesian_with_indices(all_test_train_pairs):\n",
    "    # Calculate the product of all test-train pairs across dictionaries in B\n",
    "    for combination in itertools.product(*all_test_train_pairs):\n",
    "         # Find indices of elements in their respective sets\n",
    "        indices = [s.index(elem) for s, elem in zip(all_test_train_pairs, combination)]\n",
    "        yield combination, indices\n",
    "\n",
    "def random_cartesian_with_indices(sets, num_samples):\n",
    "    for _ in range(num_samples):\n",
    "        # Randomly choose an index for each set\n",
    "        indices = [random.randint(0, len(s) - 1) for s in sets]\n",
    "        # Get the elements at the chosen indices\n",
    "        sample = [sets[i][index] for i, index in enumerate(indices)]\n",
    "        yield sample, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cartesian_test_train_pairs(sets, test_sum_ratio_th):\n",
    "    best_indices = [0]*len(sets)\n",
    "    best_sum_ratio_dif = np.inf\n",
    "    best_test_to_all_ratio = np.Inf\n",
    "    # for combination, indices in cartesian_with_indices(sets):\n",
    "    for combination, indices in random_cartesian_with_indices(test_train_pairs, 300000):\n",
    "\n",
    "        test_sum = np.sum(np.array(combination)[:,0],axis=0)\n",
    "        train_sum = np.sum(np.array(combination)[:,1],axis=0)\n",
    "        total_sum = np.sum(a=[test_sum,train_sum],axis=1)\n",
    "\n",
    "        test_sum_ratio = test_sum / total_sum[0]\n",
    "        train_sum_ratio = train_sum / total_sum[1]\n",
    "        test_to_all_ratio = total_sum[0]/np.sum(total_sum)\n",
    "        sum_ratio_dif = np.sum(np.abs(test_sum_ratio-train_sum_ratio)) # train and test set ratio difference\n",
    "\n",
    "        if (best_test_to_all_ratio+0.001 >= np.abs(test_to_all_ratio-test_sum_ratio_th)) and (sum_ratio_dif <= best_sum_ratio_dif):\n",
    "            print('# Test instances: ', test_sum)\n",
    "            print('# Train instances: ',train_sum)\n",
    "            print('# Total instances (ratio): ', total_sum, test_to_all_ratio)\n",
    "            print('Absolute sum diff: ', sum_ratio_dif)\n",
    "            print(indices)\n",
    "            best_sum_ratio_dif = sum_ratio_dif\n",
    "            best_test_to_all_ratio = np.abs(test_to_all_ratio-test_sum_ratio_th)\n",
    "            best_indices = indices\n",
    "    return best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Test instances:  [ 6 13 52 41 18  0 23  0 62 91  0  7 24 24  8  3  0  2  0 10  0 51 21]\n",
      "# Train instances:  [ 52 144 468 390 169   0  98   0 651 653  47  50 105 227 111  44  53  82  38  68   0 623 165]\n",
      "# Total instances (ratio):  [ 456 4238] 0.09714529186195142\n",
      "Absolute sum diff:  0.24339931944064974\n",
      "[14, 6, 12, 14, 17, 6, 3, 19, 0, 10, 0, 7, 19, 3, 10, 11, 2, 22, 0, 1, 11, 11, 3, 11, 11, 0, 24, 0, 11, 4, 8, 20, 11, 10, 4, 6, 17, 12, 2, 13, 13]\n",
      "# Test instances:  [ 7 15 50 41 21  0 12  0 64 68  5  8 19 26  7  4  4  4  6  2  0 82 47]\n",
      "# Train instances:  [ 51 142 470 390 166   0 109   0 649 676  42  49 110 225 112  43  49  80  32  76   0 592 139]\n",
      "# Total instances (ratio):  [ 492 4202] 0.1048146570089476\n",
      "Absolute sum diff:  0.23056964743850195\n",
      "[13, 1, 5, 4, 8, 10, 7, 6, 11, 8, 11, 14, 24, 29, 16, 8, 9, 8, 11, 1, 9, 17, 0, 9, 10, 7, 17, 2, 17, 1, 3, 20, 0, 8, 11, 6, 14, 10, 12, 16, 7]\n",
      "# Test instances:  [  6   9  66  48  23   0  20   0  71 103   3  10  17  22  12   4   1   6   1   8   0  69  25]\n",
      "# Train instances:  [ 52 148 454 383 164   0 101   0 642 641  44  47 112 229 107  43  52  78  37  70   0 605 161]\n",
      "# Total instances (ratio):  [ 524 4170] 0.11163187047294418\n",
      "Absolute sum diff:  0.20187819210280628\n",
      "[0, 6, 17, 4, 16, 0, 11, 2, 12, 10, 2, 17, 31, 4, 3, 6, 4, 26, 6, 4, 13, 16, 6, 3, 2, 9, 17, 3, 1, 7, 3, 19, 3, 5, 2, 1, 17, 19, 3, 8, 13]\n",
      "# Test instances:  [ 5 15 59 45 20  0 15  0 92 97  4  3 21 36  7  2  6  7  0 11  0 62 30]\n",
      "# Train instances:  [ 53 142 461 386 167   0 106   0 621 647  43  54 108 215 112  45  47  77  38  67   0 612 156]\n",
      "# Total instances (ratio):  [ 537 4157] 0.1144013634426928\n",
      "Absolute sum diff:  0.2010241413711095\n",
      "[23, 4, 13, 6, 8, 1, 7, 1, 14, 11, 12, 5, 31, 31, 23, 11, 2, 24, 0, 14, 22, 14, 1, 9, 13, 4, 2, 8, 10, 12, 1, 19, 18, 7, 6, 3, 11, 15, 1, 2, 14]\n",
      "# Test instances:  [ 5 14 54 39 24  0 19  0 82 78  0  8 23 34 16  1 12  9  7 13  0 87 20]\n",
      "# Train instances:  [ 53 143 466 392 163   0 102   0 631 666  47  49 106 217 103  46  41  75  31  65   0 587 166]\n",
      "# Total instances (ratio):  [ 545 4149] 0.11610566680869194\n",
      "Absolute sum diff:  0.18603089945405216\n",
      "[15, 9, 19, 7, 16, 1, 3, 13, 9, 10, 7, 18, 3, 22, 17, 3, 5, 22, 14, 2, 9, 2, 1, 12, 11, 7, 8, 0, 8, 16, 3, 14, 9, 12, 4, 7, 13, 15, 9, 16, 2]\n",
      "# Test instances:  [ 6 15 54 52 13  0 18  0 85 85  8 10 24 37 17  0  7  7 10  9  0 64 22]\n",
      "# Train instances:  [ 52 142 466 379 174   0 103   0 628 659  39  47 105 214 102  47  46  77  28  69   0 610 164]\n",
      "# Total instances (ratio):  [ 543 4151] 0.11567959096719216\n",
      "Absolute sum diff:  0.17437942353858243\n",
      "[19, 2, 11, 12, 10, 6, 14, 18, 8, 9, 9, 7, 15, 24, 0, 3, 9, 26, 14, 8, 13, 7, 11, 3, 4, 5, 2, 1, 5, 0, 20, 13, 14, 18, 6, 7, 17, 14, 10, 12, 0]\n",
      "# Test instances:  [ 6 18 63 69 28  0 18  0 98 96  2  6 13 26 11  7  2 10  2 11  0 82 24]\n",
      "# Train instances:  [ 52 139 457 362 159   0 103   0 615 648  45  51 116 225 108  40  51  74  36  67   0 592 162]\n",
      "# Total instances (ratio):  [ 592 4102] 0.12611844908393693\n",
      "Absolute sum diff:  0.13461627156166406\n",
      "[23, 3, 2, 4, 12, 3, 14, 3, 6, 2, 4, 15, 17, 19, 16, 1, 3, 14, 14, 14, 1, 0, 7, 9, 1, 1, 20, 4, 6, 12, 6, 18, 0, 15, 0, 1, 13, 11, 3, 13, 10]\n",
      "# Test instances:  [  6  16  67  51  18   0  25   0  93 104   1   6  16  34  11   4  10  11   8  14   0  80  24]\n",
      "# Train instances:  [ 52 141 453 380 169   0  96   0 620 640  46  51 113 217 108  43  43  73  30  64   0 594 162]\n",
      "# Total instances (ratio):  [ 599 4095] 0.1276097145291862\n",
      "Absolute sum diff:  0.13098591262197276\n",
      "[19, 4, 10, 3, 10, 9, 19, 3, 14, 7, 4, 14, 30, 31, 12, 10, 2, 21, 14, 8, 1, 10, 0, 9, 2, 1, 6, 9, 17, 19, 14, 8, 19, 13, 5, 6, 17, 13, 10, 11, 14]\n",
      "# Test instances:  [  3  19  74  68  25   0  19   0 102 107   5   5  18  32  17   9   5  12   0  15   0 102  44]\n",
      "# Train instances:  [ 55 138 446 363 162   0 102   0 611 637  42  52 111 219 102  38  48  72  38  63   0 572 142]\n",
      "# Total instances (ratio):  [ 681 4013] 0.14507882403067746\n",
      "Absolute sum diff:  0.11684565543774215\n",
      "[5, 13, 16, 14, 7, 4, 8, 0, 6, 6, 13, 4, 16, 20, 23, 5, 0, 24, 14, 1, 30, 1, 1, 6, 7, 9, 3, 2, 13, 18, 7, 8, 13, 13, 6, 1, 12, 5, 10, 12, 8]\n"
     ]
    }
   ],
   "source": [
    "result = get_cartesian_test_train_pairs(test_train_pairs, test_sum_ratio_th=test_sum_ratio_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 13, 16, 14, 7, 4, 8, 0, 6, 6, 13, 4, 16, 20, 23, 5, 0, 24, 14, 1, 30, 1, 1, 6, 7, 9, 3, 2, 13, 18, 7, 8, 13, 13, 6, 1, 12, 5, 10, 12, 8]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_sets(patch_dicts,best_indices,test_train_pair_indices, orig_test_train_pair_indices):\n",
    "    # with open(output_folder/'params.json','w') as f_dict:\n",
    "    #      json.dump(f_dict,\n",
    "    #                {'patch_dicts':patch_dicts,\n",
    "    #                 'best_indices':best_indices,\n",
    "    #                 'test_train_pair_indices':test_train_pair_indices,\n",
    "    #                 'orig_test_train_pair_indices':orig_test_train_pair_indices})\n",
    "    # for file_name, patch_dict in patch_dicts.items():\n",
    "    file_names = list(patch_dicts.keys())\n",
    "    tasks = get_all_satellitepy_keys()\n",
    "    for i, ind in enumerate(best_indices):\n",
    "        # i : original image index\n",
    "        # ind : patch index within the original image\n",
    "\n",
    "        orig_ind = orig_test_train_pair_indices[i][ind]\n",
    "        # Save labels\n",
    "        file_name = Path(file_names[i]).stem\n",
    "        print(f'Processing {file_name}')\n",
    "        # if train_img_path.is_file():\n",
    "            #  print(f'{file_name} exists in the destination train folder, skipped...')\n",
    "            #  continue\n",
    "        patch_dict = patch_dicts[file_names[i]]\n",
    "        label_path = label_folder / file_names[i]\n",
    "        label = read_label(label_path=label_path,label_format=label_format)\n",
    "        test_label = init_satellitepy_label()\n",
    "        train_label = init_satellitepy_label()\n",
    "        x_0, y_0 = patch_dict['start_coords'][orig_ind]\n",
    "\n",
    "        # Set test and train labels\n",
    "        ## Unique values are calculated previously for test_train_pairs\n",
    "        ## Use the corresponding unique value indices to find the train-test pair indices\n",
    "        test_indices, train_indices = test_train_pair_indices[i][ind]\n",
    "\n",
    "        # print(test_indices)\n",
    "        print(f\"Test image has {len(test_indices)} airplanes.\")\n",
    "        for task in tasks:\n",
    "            task_values = get_satellitepy_dict_values(label,task=task)\n",
    "            test_task_values = []\n",
    "            train_task_values = []\n",
    "            for task_value_i, task_value in enumerate(task_values):\n",
    "                if task_value_i in test_indices:\n",
    "                    test_task_values.append(task_value)\n",
    "                elif task_value_i in train_indices:\n",
    "                    train_task_values.append(task_value)\n",
    "            test_label = set_satellitepy_dict_values(test_label,task=task,value=test_task_values)\n",
    "            train_label = set_satellitepy_dict_values(train_label,task=task,value=train_task_values)\n",
    "\n",
    "        # shift test bboxes\n",
    "        for bbox_task in ['obboxes','hbboxes']:\n",
    "            bbox_values = get_satellitepy_dict_values(test_label,task=bbox_task)\n",
    "            shifted_bbox_values = (np.array(bbox_values) - [x_0, y_0]).tolist()\n",
    "            test_label = set_satellitepy_dict_values(test_label,task=bbox_task,value=shifted_bbox_values)\n",
    "\n",
    "        test_file_name = f'{file_name}_x0_{x_0}_y0_{y_0}_sz_{test_img_sz}'\n",
    "\n",
    "        # Save label files\n",
    "        ## Test\n",
    "        for test_label_folder in [test_label_png_folder,test_label_tif_folder]:\n",
    "            test_label_path = test_label_folder / f\"{test_file_name}.json\"\n",
    "            with open(str(test_label_path), 'w+') as f:\n",
    "                json.dump(test_label, f, indent=4)\n",
    "        ## Train\n",
    "        for train_label_folder in [train_label_png_folder,train_label_tif_folder]:\n",
    "            train_label_path = train_label_folder / f\"{file_name}.json\"\n",
    "            with open(str(train_label_path), 'w+') as f:\n",
    "                json.dump(train_label, f, indent=4)\n",
    "\n",
    "        # Save images\n",
    "        ## Train\n",
    "        img_path=str(img_folder/f\"{file_name}.{input_img_ext}\")\n",
    "        with rasterio.open(img_path) as src:\n",
    "            img_array = src.read()  # Shape: (C, H, W)\n",
    "            meta = src.meta.copy()\n",
    "            window = Window(x_0, y_0, test_img_sz, test_img_sz)\n",
    "            test_img_array = src.read(window=window)\n",
    "        train_mask = np.ones_like(img_array, dtype=np.uint8)\n",
    "        train_mask[:, y_0:y_0+test_img_sz, x_0:x_0+test_img_sz] = 0\n",
    "        train_img_tif = img_array*train_mask\n",
    "        \n",
    "        ### tif\n",
    "        train_img_tif_path = str(train_img_tif_folder/f\"{file_name}.tif\")\n",
    "        print(f\"Saving train image to {train_img_tif_path}\")\n",
    "        with rasterio.open(train_img_tif_path, 'w', **src.meta) as dst:\n",
    "            dst.write(train_img_tif)\n",
    "\n",
    "        ### PNG\n",
    "        img = np.transpose(train_img_tif, axes=(1, 2, 0))  # Shape: (H, W, C)\n",
    "            \n",
    "        lo = np.percentile(img, 1) # lo_percent\n",
    "        hi = np.percentile(img, 99) # hi_percent\n",
    "        img_clipped = np.clip(img, lo, hi)\n",
    "        img_normalized = (img_clipped - lo) / (hi - lo) * 255.0\n",
    "        train_img_png = np.clip(img_normalized, 0, 255).astype(np.uint8)\n",
    "        train_img_png_path = train_img_png_folder/f\"{file_name}.png\"\n",
    "        cv2.imwrite(str(train_img_png_path),train_img_png)\n",
    "\n",
    "        ## Test\n",
    "        ### tif\n",
    "        # with rasterio.open(img_path) as src:\n",
    "\n",
    "        meta.update({\n",
    "            'height': test_img_sz,\n",
    "            'width': test_img_sz,\n",
    "            'transform': rasterio.windows.transform(window, src.transform)\n",
    "        })\n",
    "\n",
    "        test_img_tif_path = str(test_img_tif_folder / f\"{file_name}.tif\")\n",
    "        with rasterio.open(test_img_tif_path, 'w', **meta) as dst:\n",
    "            dst.write(test_img_array)\n",
    "        ### PNG\n",
    "        img = np.transpose(test_img_array, axes=(1, 2, 0))  # Shape: (H, W, C)\n",
    "        lo = np.percentile(img, 1) # lo_percent\n",
    "        hi = np.percentile(img, 99) # hi_percent\n",
    "        img_clipped = np.clip(img, lo, hi)\n",
    "        img_normalized = (img_clipped - lo) / (hi - lo) * 255.0\n",
    "        test_img_png = np.clip(img_normalized, 0, 255).astype(np.uint8)\n",
    "        test_img_png_path = test_img_png_folder/f\"{file_name}.png\"\n",
    "        cv2.imwrite(str(test_img_png_path),test_img_png)\n",
    "\n",
    "        # img = read_img(img_path=str(img_folder/f\"{file_name}.{input_img_ext}\"), module=img_read_module)\n",
    "        # test_img = img[y_0:y_0+test_img_sz, x_0:x_0+test_img_sz, :]\n",
    "        # train_mask = np.ones_like(img, dtype=np.uint8)\n",
    "        # train_mask[y_0:y_0+test_img_sz, x_0:x_0+test_img_sz, :] = 0\n",
    "        # train_img = img*train_mask\n",
    "        # cv2.imwrite(str(train_img_path),train_img)\n",
    "        # cv2.imwrite(str(test_img_folder/f\"{test_file_name}.png\"),test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Amsterdam_23MAR14104929\n",
      "Test image has 10 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Amsterdam_23MAR14104929.tif\n",
      "Processing Bangkok_23FEB21040003\n",
      "Test image has 9 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Bangkok_23FEB21040003.tif\n",
      "Processing Beijing_23SEP13031225\n",
      "Test image has 10 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Beijing_23SEP13031225.tif\n",
      "Processing Beijing_Capital_International_22DEC04031345\n",
      "Test image has 12 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Beijing_Capital_International_22DEC04031345.tif\n",
      "Processing Cairo_24JAN04084426\n",
      "Test image has 63 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Cairo_24JAN04084426.tif\n",
      "Processing Cairo_24JAN29084910\n",
      "Test image has 6 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Cairo_24JAN29084910.tif\n",
      "Processing Charles_De_Gaulle_23MAY29105259\n",
      "Test image has 1 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Charles_De_Gaulle_23MAY29105259.tif\n",
      "Processing Charlotte_Douglas_International_Airport_24JAN18161805\n",
      "Test image has 7 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Charlotte_Douglas_International_Airport_24JAN18161805.tif\n",
      "Processing Chengdu_Shuangliu_International_Airport_23NOV27035335\n",
      "Test image has 2 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Chengdu_Shuangliu_International_Airport_23NOV27035335.tif\n",
      "Processing Chongqing_Jiangbei_International_Airport_23JUL16034146\n",
      "Test image has 19 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Chongqing_Jiangbei_International_Airport_23JUL16034146.tif\n",
      "Processing Dallas_Fort_Worth_21JUL13170358\n",
      "Test image has 1 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Dallas_Fort_Worth_21JUL13170358.tif\n",
      "Processing Dallas_Fort_Worth_22JUN16172659\n",
      "Test image has 83 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Dallas_Fort_Worth_22JUN16172659.tif\n",
      "Processing Dallas_Fort_Worth_23FEB22171239\n",
      "Test image has 14 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Dallas_Fort_Worth_23FEB22171239.tif\n",
      "Processing Denver_International_Airport_23JUN19175130\n",
      "Test image has 32 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Denver_International_Airport_23JUN19175130.tif\n",
      "Processing Denver_International_Airport_24JAN23173709\n",
      "Test image has 25 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Denver_International_Airport_24JAN23173709.tif\n",
      "Processing Dubai_International_23DEC03070208\n",
      "Test image has 20 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Dubai_International_23DEC03070208.tif\n",
      "Processing Frankfurt_22MAR22103647\n",
      "Test image has 15 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Frankfurt_22MAR22103647.tif\n",
      "Processing George_Bush_Int_Airport_23DEC05171248\n",
      "Test image has 42 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/George_Bush_Int_Airport_23DEC05171248.tif\n",
      "Processing Guangzhou_Baiyun_International_Airport_22OCT10032231\n",
      "Test image has 51 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Guangzhou_Baiyun_International_Airport_22OCT10032231.tif\n",
      "Processing Harry_Reid_International_Airport_23NOV25183153\n",
      "Test image has 6 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Harry_Reid_International_Airport_23NOV25183153.tif\n",
      "Processing Hartsfield_Jackson_23SEP23162708\n",
      "Test image has 2 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Hartsfield_Jackson_23SEP23162708.tif\n",
      "Processing Houston_23SEP01171626\n",
      "Test image has 1 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Houston_23SEP01171626.tif\n",
      "Processing Istanbul_23JUL12090526\n",
      "Test image has 20 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Istanbul_23JUL12090526.tif\n",
      "Processing John_F_Kennedy_Airport_23FEB05160037\n",
      "Test image has 2 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/John_F_Kennedy_Airport_23FEB05160037.tif\n",
      "Processing King_Fahd_23JUL18072645\n",
      "Test image has 1 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/King_Fahd_23JUL18072645.tif\n",
      "Processing King_Fahd_24FEB13071831\n",
      "Test image has 6 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/King_Fahd_24FEB13071831.tif\n",
      "Processing Madrid_23MAR28111507\n",
      "Test image has 7 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Madrid_23MAR28111507.tif\n",
      "Processing Miami_International_Airport_23OCT17160943\n",
      "Test image has 49 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Miami_International_Airport_23OCT17160943.tif\n",
      "Processing O_Hare_Int_Airport_22JUN14165415\n",
      "Test image has 2 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/O_Hare_Int_Airport_22JUN14165415.tif\n",
      "Processing O_Hare_Int_Airport_22OCT23164249\n",
      "Test image has 5 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/O_Hare_Int_Airport_22OCT23164249.tif\n",
      "Processing O_Hare_Int_Airport_23FEB28165710\n",
      "Test image has 10 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/O_Hare_Int_Airport_23FEB28165710.tif\n",
      "Processing Orlando_International_Airport_23MAY30161635\n",
      "Test image has 2 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Orlando_International_Airport_23MAY30161635.tif\n",
      "Processing Orlando_International_Airport_23NOV07161938\n",
      "Test image has 17 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Orlando_International_Airport_23NOV07161938.tif\n",
      "Processing Orlando_International_Airport_24FEB16160844\n",
      "Test image has 7 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Orlando_International_Airport_24FEB16160844.tif\n",
      "Processing Shanghai_23APR13022829\n",
      "Test image has 12 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Shanghai_23APR13022829.tif\n",
      "Processing Shenzhen_23APR28030710\n",
      "Test image has 39 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Shenzhen_23APR28030710.tif\n",
      "Processing Singapore_22SEP27034737\n",
      "Test image has 2 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Singapore_22SEP27034737.tif\n",
      "Processing Soekarno_22MAR27031534\n",
      "Test image has 1 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Soekarno_22MAR27031534.tif\n",
      "Processing Tokyo_Haneda_Airport_24JAN30012936\n",
      "Test image has 12 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Tokyo_Haneda_Airport_24JAN30012936.tif\n",
      "Processing Toronto_23MAY27162713\n",
      "Test image has 8 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Toronto_23MAY27162713.tif\n",
      "Processing Washington_Dulles_23MAR30160557\n",
      "Test image has 48 airplanes.\n",
      "Saving train image to /mnt/2tb-1/satellitepy/data/FR24_sets_v2/tif/train/images/Washington_Dulles_23MAR30160557.tif\n"
     ]
    }
   ],
   "source": [
    "save_sets(patch_dicts=patch_dicts,\n",
    "    best_indices=result,\n",
    "    test_train_pair_indices=test_train_pair_indices,\n",
    "    orig_test_train_pair_indices=orig_test_train_pair_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_labels_on_images(image_folder=test_img_folder,\n",
    "#         label_folder=test_label_folder,\n",
    "#         mask_folder=None,\n",
    "#         label_format='satellitepy',\n",
    "#         img_read_module='cv2',\n",
    "#         out_folder=Path('/home/murat/Projects/satellitepy/docs/temp_fineair_set'),\n",
    "#         tasks=['coarse-class','obboxes'],\n",
    "#         rescaling=1.0,\n",
    "#         interpolation_method=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_satellitepy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
